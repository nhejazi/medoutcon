################################################################################

#' Fit mediator-outcome confounder score without conditioning on mediators
#'
#' @param data A \code{data.table} containing the observed data, with columns
#'  in the order specified by the NPSEM (Y, Z, L, A, W), with column names set
#'  appropriately based on the original input data. Such a structure is merely
#'  a convenience utility to passing data around to the various core estimation
#'  routines and is automatically generated as part of a call to the user-facing
#'  wrapper function \code{medshift}.
#' @param valid_data A holdout data set, with columns exactly matching those
#'  appearing in the preceding argument \code{data}, to be used for estimation
#'  via cross-fitting. Optional, defaulting to \code{NULL}.
#' @param contrast ...
#' @param lrnr_stack A \code{Stack} object, or other learner class (inheriting
#'  from \code{Lrnr_base}), containing a single or set of instantiated learners
#'  from the \code{sl3} package, to be used in fitting a model for the
#'  propensity score, i.e., g = P(A | W).
#' @param w_names A \code{character} vector of the names of the columns that
#'  correspond to baseline covariates (W). The input for this argument is
#'  automatically generated by a call to the wrapper function \code{medshift}.
#'
#' @importFrom data.table as.data.table copy setnames ":="
#' @importFrom sl3 sl3_Task
#
fit_q_mech <- function(data,
                       valid_data = NULL,
                       contrast,
                       lrnr_stack,
                       w_names) {
  # set argument defaults
  shift_type <- match.arg(shift_type)

  # use full data for counterfactual prediction if no validation data provided
  if (is.null(valid_data)) {
    # copy full data
    data_intervene <- data.table::copy(data)
  } else {
    # copy only validation data
    data_intervene <- data.table::copy(valid_data)
  }
  data_intervene[, A := A + contrast]

  # construct task for fitting score for mediator-outcome confounder
  q_intervened_task <- sl3::sl3_Task$new(
    data = data_intervene,
    covariates = c("A", w_names),
    outcome_type = "binomial",
    outcome = "L"
  )

  # fitting score for mediator-outcome confounder
  q_fit <- lrnr_stack$train(q_intervened_task)

  # get predictions from natural propensity score model for intervened data
  q_intervened_pred <- q_fit$predict(g_intervened_task)

  # bounding to numerical precision and for positivity considerations
  out_q_mat <- cbind(q_intervened_pred)
  out_q_est <- apply(out_q_mat, 2, function(x) {
                       x_precise <- bound_precision(x)
                       x_bounded <- bound_propensity(x_precise)
                       return(x_bounded)
                    })
  out_q_est <- data.table::as.data.table(out_q_est)
  data.table::setnames(out_q_est, c("q_pred"))

  # output
  out <- list(
    q_est = out_q_est,
    q_fit = q_fit
  )
  return(out)
}

################################################################################

#' Fit mediator-outcome confounder score while conditioning on mediators
#'
#' @param data A \code{data.table} containing the observed data, with columns
#'  in the order specified by the NPSEM (Y, Z, L, A, W), with column names set
#'  appropriately based on the original input data. Such a structure is merely
#'  a convenience utility to passing data around to the various core estimation
#'  routines and is automatically generated as part of a call to the user-facing
#'  wrapper function \code{medshift}.
#' @param valid_data A holdout data set, with columns exactly matching those
#'  appearing in the preceding argument \code{data}, to be used for estimation
#'  via cross-fitting. Optional, defaulting to \code{NULL}.
#' @param contrast ...
#' @param lrnr_stack A \code{Stack} object, or other learner class (inheriting
#'  from \code{Lrnr_base}), containing a single or set of instantiated learners
#'  from the \code{sl3} package, to be used in fitting a model for the
#'  propensity score, i.e., g = P(A | W).
#' @param z_names A \code{character} vector of the names of the columns that
#'  correspond to mediators (Z). The input for this argument is automatically
#'  generated by a call to the wrapper function \code{medshift}.
#' @param w_names A \code{character} vector of the names of the columns that
#'  correspond to baseline covariates (W). The input for this argument is
#'  automatically generated by a call to the wrapper function \code{medshift}.
#'
#' @importFrom data.table as.data.table copy setnames ":="
#' @importFrom sl3 sl3_Task
#
fit_r_mech <- function(data,
                       valid_data = NULL,
                       contrast,
                       lrnr_stack,
                       z_names,
                       w_names) {
  # set argument defaults
  shift_type <- match.arg(shift_type)

  # use full data for counterfactual prediction if no validation data provided
  if (is.null(valid_data)) {
    # copy full data
    data_intervene <- data.table::copy(data)
  } else {
    # copy only validation data
    data_intervene <- data.table::copy(valid_data)
  }
  data_intervene[, A := A + contrast]

  # construct task for fitting score for mediator-outcome confounder
  r_intervened_task <- sl3::sl3_Task$new(
    data = data_intervene,
    covariates = c("A", z_names, w_names),
    outcome_type = "binomial",
    outcome = "L"
  )

  # fitting score for mediator-outcome confounder
  r_fit <- lrnr_stack$train(r_intervened_task)

  # get predictions from natural propensity score model for intervened data
  r_intervened_pred <- r_fit$predict(r_intervened_task)

  # bounding to numerical precision and for positivity considerations
  out_r_mat <- cbind(r_intervened_pred)
  out_r_est <- apply(out_r_mat, 2, function(x) {
                       x_precise <- bound_precision(x)
                       x_bounded <- bound_propensity(x_precise)
                       return(x_bounded)
                    })
  out_r_est <- data.table::as.data.table(out_r_est)
  data.table::setnames(out_r_est, c("r_pred"))

  # output
  out <- list(
    r_est = out_r_est,
    r_fit = r_fit
  )
  return(out)
}

################################################################################
#fit_u_mech <- function(data,
                       #lrnr_stack,
                       #m_output,
                       #q_output,
                       #r_output,
                       #e_output,
                       #e_output_intv,
                       #w_names) {

################################################################################
#fit_u_mech <- function(data,
                       #lrnr_stack,
                       #m_output_intv,
                       #q_output_intv,
                       #w_names) {

################################################################################

#' Cross-validated evaluation of EIF with mediator-outcome confounder
#'
#' @param fold Object specifying cross-validation folds as generated by a call
#'  to \code{origami::make_folds}.
#' @param data A \code{data.table} containing the observed data, with columns
#'  in the order specified by the NPSEM (Y, Z, A, W), with column names set
#'  appropriately based on the original input data. Such a structure is merely
#'  a convenience utility to passing data around to the various core estimation
#'  routines and is automatically generated as part of a call to the user-facing
#'  wrapper function \code{medshift}.
#' @param delta A \code{numeric} value indicating the degree of shift in the
#'  intervention to be used in defining the causal quantity of interest. In the
#'  case of binary interventions, this takes the form of an incremental
#'  propensity score shift, acting as a multiplier of the probability with which
#'  a given observational unit receives the intervention (EH Kennedy, 2018,
#'  JASA; <doi:10.1080/01621459.2017.1422737>).
#' @param lrnr_stack_g A \code{Stack} object, or other learner class (inheriting
#'  from \code{Lrnr_base}), containing a single or set of instantiated learners
#'  from the \code{sl3} package, to be used in fitting a model for the
#'  propensity score, i.e., g = P(A | W).
#' @param lrnr_stack_e A \code{Stack} object, or other learner class (inheriting
#'  from \code{Lrnr_base}), containing a single or set of instantiated learners
#'  from the \code{sl3} package, to be used in fitting a cleverly parameterized
#'  propensity score that includes the mediators, i.e., e = P(A | Z, W).
#' @param lrnr_stack_m A \code{Stack} object, or other learner class (inheriting
#'  from \code{Lrnr_base}), containing a single or set of instantiated learners
#'  from the \code{sl3} package, to be used in fitting the outcome regression,
#'  i.e., m(A, Z, W).
#' @param lrnr_stack_phi A \code{Stack} object, or other learner class
#'  (inheriting from \code{Lrnr_base}), containing a single or set of
#'  instantiated learners from the \code{sl3} package, to be used in fitting a
#'  reduced regression useful for computing the efficient one-step estimator,
#'  i.e., phi(W) = E[m(A = 1, Z, W) - m(A = 0, Z, W) | W).
#' @param w_names A \code{character} vector of the names of the columns that
#'  correspond to baseline covariates (W). The input for this argument is
#'  automatically generated by a call to the wrapper function \code{medshift}.
#' @param z_names A \code{character} vector of the names of the columns that
#'  correspond to mediators (Z). The input for this argument is automatically
#'  generated by a call to the wrapper function \code{medshift}.
#' @param shift_type A choice of the type of stochastic treatment regime to use
#'  -- either \code{"mtp"} for a modified treatment policy that shifts the
#'  center of the observed intervention distribution by the scalar \code{delta}
#'  or \code{"ipsi"} for an incremental propensity score shift that multiples
#'  the odds of receiving the intervention by the scalar \code{delta}.
#'
#' @importFrom data.table data.table
#' @importFrom origami training validation fold_index
#'
#' @keywords internal
#
cv_eif_moc <- function(fold,
                       data,
                       delta,
                       lrnr_stack_g,
                       lrnr_stack_e,
                       lrnr_stack_m,
                       lrnr_stack_phi,
                       w_names,
                       z_names,
                       shift_type = c("ipsi", "mtp")) {
  # set IPSI shift as default for now...
  shift_type <- match.arg(shift_type)

  # make training and validation data
  train_data <- origami::training(data)
  valid_data <- origami::validation(data)

  # 1) fit regression for incremental propensity score intervention
  g_out <- fit_g_mech(
    data = train_data, valid_data = valid_data,
    delta = delta,
    lrnr_stack = lrnr_stack_g, w_names = w_names,
    shift_type = shift_type
  )

  # 2) fit clever regression for treatment, conditional on mediators
  e_out <- fit_e_mech(
    data = train_data, valid_data = valid_data,
    lrnr_stack = lrnr_stack_e,
    z_names = z_names, w_names = w_names,
    shift_type = shift_type
  )

  # 3) fit regression for incremental propensity score intervention
  m_out <- fit_m_mech(
    data = train_data, valid_data = valid_data,
    lrnr_stack = lrnr_stack_m,
    z_names = z_names, w_names = w_names,
    shift_type = shift_type
  )

  # 4) difference-reduced dimension regression for phi
  if (shift_type == "ipsi") {
    phi_est <- fit_phi_mech_ipsi(
      data = valid_data, lrnr_stack = lrnr_stack_phi,
      m_output = m_out, w_names = w_names
    )
  } else if (shift_type == "mtp") {
    phi_est <- fit_phi_mech_mtp(
      data = valid_data, lrnr_stack = lrnr_stack_phi,
      m_output = m_out, e_output = e_out,
      g_output = g_out, w_names = w_names
    )
  }

  if (shift_type == "ipsi") {
    # get indices of treated and control units in validation data
    idx_A1 <- which(valid_data$A == 1)
    idx_A0 <- which(valid_data$A == 0)

    # compute component Dzw from nuisance parameters
    Dzw_groupwise <- compute_Dzw(g_output = g_out, m_output = m_out,
                                 shift_type = shift_type)
    Dzw <- Dzw_groupwise$dzw_cntrl + Dzw_groupwise$dzw_treat

    # compute component Da from nuisance parameters
    g_pred_A1 <- g_out$g_est$g_pred_A1
    g_pred_A0 <- g_out$g_est$g_pred_A0
    Da_numerator <- delta * phi_est * (valid_data$A - g_pred_A1)
    Da_denominator <- (delta * g_pred_A1 + g_pred_A0)^2
    Da <- Da_numerator / Da_denominator

    # compute component Dy from nuisance parameters
    ipw_groupwise <- compute_ipw(
      g_output = g_out, e_output = e_out,
      idx_treat = idx_A1, idx_cntrl = idx_A0,
      shift_type = shift_type
    )

    # stabilize weights in AIPW by dividing by sample average since E[g/e] = 1
    mean_ipw <- ipw_groupwise$mean_ipw
    g_shifted <- ipw_groupwise$g_shifted
    e_pred <- ipw_groupwise$e_pred
    sipw <- ((g_shifted / e_pred) / mean_ipw)

    # extract outcome component mechanism for estimting Dy
    m_pred_obs <- rep(NA, nrow(valid_data))
    m_pred_A1_obs <- m_out$m_pred$m_pred_A1[idx_A1]
    m_pred_A0_obs <- m_out$m_pred$m_pred_A0[idx_A0]
    m_pred_obs[idx_A1] <- m_pred_A1_obs
    m_pred_obs[idx_A0] <- m_pred_A0_obs

    # assemble Dy component estimate
    Dy <- sipw * (valid_data$Y - m_pred_obs)

  } else if (shift_type == "mtp") {
    # compute component Dzw from nuisance parameters
    Dzw_est <- compute_Dzw(g_output = g_out, m_output = m_out,
                           shift_type = shift_type)
    Dzw <- rep(as.numeric(sum(Dzw_est$dzw)), times = nrow(g_out$g_est))

    # compute component Da from nuisance parameters
    g_natural <- g_out$g_est$g_natural
    a_natural <- g_out$a_vals$a_natural

    # approximate Monte Carlo integral using inverse uniform weighting
    int_Da_phi <- integrate_over_g(g_mech = g_natural,
                                   a_vals = a_natural,
                                   weighting = phi_est)
    Da <- phi_est - sum(int_Da_phi)

    # compute component Dy from nuisance parameters
    ipw_out <- compute_ipw(
      g_output = g_out, e_output = e_out,
      shift_type = shift_type
    )

    # stabilize weights in AIPW by dividing by sample average since E[g/e] = 1
    mean_ipw <- ipw_out$mean_ipw
    g_shifted <- ipw_out$g_shifted
    e_pred <- ipw_out$e_pred
    sipw <- ((g_shifted / e_pred) / mean_ipw)

    # extract outcome mechanism estimate under natural intervention value
    m_pred <- m_out$m_pred$m_natural

    # assemble Dy component estimate
    Dy <- sipw * (valid_data$Y - m_pred)
  }

  # output list
  out <- list(data.table::data.table(
    Dy = Dy, Da = Da, Dzw = Dzw,
    fold = origami::fold_index()
  ))
  return(out)
}
