<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Efficient causal mediation analysis with intermediate confounders • medoutcon</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/readable/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Efficient causal mediation analysis with intermediate confounders">
<meta property="og:description" content="medoutcon">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">medoutcon</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.5</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/intro_medoutcon.html">Efficient causal mediation analysis with intermediate confounders</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/nhejazi/medoutcon/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Efficient causal mediation analysis with intermediate confounders</h1>
                        <h4 class="author">
<a href="https://nimahejazi.org">Nima Hejazi</a>, <a href="https://www.idiaz.xyz/">Iván Díaz</a>, and <a href="https://kararudolph.github.io/">Kara Rudolph</a>
</h4>
            
            <h4 class="date">2021-05-03</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/nhejazi/medoutcon/blob/master/vignettes/intro_medoutcon.Rmd"><code>vignettes/intro_medoutcon.Rmd</code></a></small>
      <div class="hidden name"><code>intro_medoutcon.Rmd</code></div>

    </div>

    
    
<div id="background-and-motivations" class="section level1">
<h1 class="hasAnchor">
<a href="#background-and-motivations" class="anchor"></a>Background and Motivations</h1>
<p>An exposure of interest often affects an outcome directly, or indirectly by the mediation of some intermediate variables. Identifying and quantifying the mechanisms underlying causal effects is an increasingly popular endeavor in public health, medicine, and the social sciences, as knowledge of such mechanisms can improve understanding of both <em>why and how</em> treatments can be effective. Such mechanistic knowledge may be arguably even more important in cases where treatments result in unanticipated ineffective or even harmful effects.</p>
<p>Traditional techniques for mediation analysis fare poorly in the face of intermediate confounding. Classical parameters like the natural (in)direct effects face a lack of identifiability in cases where mediator-outcome (i.e., intermediate) confounders affected by exposure complicate the relationship between the exposure, mediators, and outcome. <span class="citation">Dı́az et al. (2020)</span> provide a theoretical and computational study of the properties of newly developed interventional (in)direct effect estimands within the non-parametric statistical model. Among their contributions, <span class="citation">Dı́az et al. (2020)</span></p>
<ul>
<li>derive the efficient influence function (EIF), an key object in semiparametric efficiency theory;</li>
<li>use the EIF to develop two asymptotically optimal, non-parametric estimators, each of which is capable of leveraging machine learning for the estimation of nuisance parameters; and</li>
<li>present theoretical conditions under which their proposed estimators are consistent, multiply robust, and efficient.</li>
</ul>
</div>
<div id="problem-setup-and-notation" class="section level1">
<h1 class="hasAnchor">
<a href="#problem-setup-and-notation" class="anchor"></a>Problem Setup and Notation</h1>
<p>The problem addressed by the work of <span class="citation">Dı́az et al. (2020)</span> may be represented by the following nonparametric structural equation model (NPSEM): <span class="math display">\[\begin{align*}
  W &amp;= f_W(U_W); A = f_A(W, U_A); Z=f_Z(W, A, U_Z);\\ \nonumber
  M &amp;= f_M(W, A, Z, U_M); Y = f_Y(W, A, Z, M, U_Y).
\end{align*}\]</span> In the NPSEM, <span class="math inline">\(W\)</span> denotes a vector of observed pre-treatment covariates, <span class="math inline">\(A\)</span> denotes a categorical treatment variable, <span class="math inline">\(Z\)</span> denotes an intermediate confounder affected by treatment, <span class="math inline">\(M\)</span> denotes a (possibly multivariate) mediator, and <span class="math inline">\(Y\)</span> denotes a continuous or binary outcome. The vector of exogenous factors <span class="math inline">\(U=(U_W,U_A,U_Z,U_M,U_Y)\)</span>, and the functions <span class="math inline">\(f\)</span>, are assumed deterministic but unknown. Importantly, the NPSEM encodes a time-ordering between these variables and allows the evaluation of counterfactual quantities defined by intervening on a set of nodes of the NPSEM. The observed data unit can be represented by the random variable <span class="math inline">\(O = (W, A, Z, M, Y)\)</span>; we consider access to <span class="math inline">\(O_1, \ldots, O_n\)</span>, a sample of <span class="math inline">\(n\)</span> i.i.d. observations of <span class="math inline">\(O\)</span>.</p>
<p><span class="citation">Dı́az et al. (2020)</span> additionally define the following parameterizations, familiarity with which will be useful for using the <a href="https://github.com/nhejazi/medoutcon"><code>medoutcon</code> <code>R</code> package</a>. In particular, these authors define <span class="math inline">\(g(a \mid w)\)</span> as the probability mass function of <span class="math inline">\(A = a\)</span> conditional on <span class="math inline">\(W = w\)</span> and use <span class="math inline">\(h(a \mid m, w)\)</span> to denote the probability mass function of <span class="math inline">\(A = a\)</span> conditional on <span class="math inline">\((M, W) = (m, w)\)</span>. Further, <span class="citation">Dı́az et al. (2020)</span> use <span class="math inline">\(b(a, z, m, w)\)</span> to denote the outcome regression function <span class="math inline">\(\mathbb{E}(Y \mid A = a, Z = z, M = m, W = w)\)</span>, as well as <span class="math inline">\(q(z \mid a,w)\)</span> and <span class="math inline">\(r(z \mid a, m, w)\)</span> to denote the corresponding conditional densities of <span class="math inline">\(Z\)</span>.</p>
</div>
<div id="interventional-indirect-effects" class="section level1">
<h1 class="hasAnchor">
<a href="#interventional-indirect-effects" class="anchor"></a>Interventional (In)Direct Effects</h1>
<p><span class="citation">Dı́az et al. (2020)</span> define the <em>total effect</em> of <span class="math inline">\(A\)</span> on <span class="math inline">\(Y\)</span> in terms of a contrast between two user-supplied values <span class="math inline">\(a', a^{\star} \in \mathcal{A}\)</span>. Examination of the NPSEM reveals that there are four paths involved in this effect, namely <span class="math inline">\(A \rightarrow Y\)</span>, <span class="math inline">\(A \rightarrow M \rightarrow Y\)</span>, <span class="math inline">\(A \rightarrow Z \rightarrow Y\)</span>, and <span class="math inline">\(A \rightarrow Z \rightarrow M \rightarrow Y\)</span>. Mediation analysis has classically considered the <em>natural direct effect</em> (NDE) and the <em>natural indirect effect</em> (NIE), which are defined as <span class="math inline">\(\mathbb{E}_c(Y_{a', M_{a^{\star}}} - Y_{a^{\star}, M_{a^{\star}}})\)</span> and <span class="math inline">\(\mathbb{E}_c(Y_{a',M_{a'}} - Y_{a',M_{a^{\star}}})\)</span>, respectively. The natural direct effect measures the effect through paths <em>not</em> involving the mediator (<span class="math inline">\(A \rightarrow Y\)</span> and <span class="math inline">\(A \rightarrow Z \rightarrow Y\)</span>), whereas the natural indirect effect measures the effect through paths involving the mediator (<span class="math inline">\(A \rightarrow M \rightarrow Y\)</span> and <span class="math inline">\(A \rightarrow Z \rightarrow M \rightarrow Y\)</span>). As the sum of the natural direct and indirect effects equals the average treatment effect <span class="math inline">\(\mathbb{E}_c(Y_1-Y_0)\)</span>, this effect decomposition is appealing. Unfortunately, the natural direct and indirect effects are not generally identified in the presence of an intermediate confounder affected by treatment.</p>
<p>To circumvent this issue, <span class="citation">Dı́az et al. (2020)</span> define the direct and indirect effects using stochastic interventions on the mediator, following a strategy previously outlined by <span class="citation">VanderWeele, Vansteelandt, and Robins (2014)</span> and <span class="citation">Rudolph et al. (2017)</span>, among others. Let <span class="math inline">\(G_a\)</span> denote a random draw from the conditional distribution of <span class="math inline">\(M_a\)</span> conditional on <span class="math inline">\(W\)</span>. Consider the effect of <span class="math inline">\(A\)</span> on <span class="math inline">\(Y\)</span> defined as the difference in expected outcome in hypothetical worlds in which <span class="math inline">\((A,M) = (a', G_{a'})\)</span> versus <span class="math inline">\((A,M) = (a^{\star}, G_{a^{\star}})\)</span> with probability one, which may be decomposed into direct and indirect effects as follows <span class="math display">\[\begin{equation*}
\mathbb{E}_c(Y_{a', G_{a'}} - Y_{a^{\star}, G_{a^{\star}}}) =
  \underbrace{\mathbb{E}_c(Y_{a', G_{a'}} - Y_{a',
    G_{a^{\star}}})}_{\text{Indirect effect (through $M$)}} +
  \underbrace{\mathbb{E}_c(Y_{a', G_{a^{\star}}} - Y_{a^{\star},
      G_{a^{\star}}})}_{\text{Direct effect (not through $M$)}}.
\end{equation*}\]</span> Like the natural direct effect, this interventional direct effect measures the effects through paths not involving the mediator. Likewise, the interventional indirect effect measures the effect through paths involving the mediator. Note, however, that natural and interventional mediation effects have different interpretations. That is, the interventional indirect effect measures the effect of fixing the exposure at <span class="math inline">\(a'\)</span> while setting the mediator to a random draw <span class="math inline">\(G_{a^{\star}}\)</span> from those with exposure <span class="math inline">\(a'\)</span> versus a random draw <span class="math inline">\(G_{a'}\)</span> from those with exposure <span class="math inline">\(a^{\star}\)</span>, given covariates <span class="math inline">\(W\)</span>. As is clear from the effect decomposition, the term <span class="math inline">\(\theta_c = \mathbb{E}_c(Y_{a', G_{a^{\star}}})\)</span> is required for estimation of both the interventional direct and indirect effects; thus, <span class="citation">Dı́az et al. (2020)</span> focus on estimation of this quantity. Importantly, it has been shown that <span class="math inline">\(\theta_c\)</span> is identified by the statistical functional <span class="math display">\[\begin{equation*}
  \theta = \int b(a', z, m, w) q(z \mid a', w) p(m \mid a^{\star}, w)
    p(w) d\nu(w,z,m)
\end{equation*}\]</span> under a set of standard identifiability conditions <span class="citation">(VanderWeele, Vansteelandt, and Robins 2014)</span>, which are further reviewed in <span class="citation">Dı́az et al. (2020)</span>.</p>
</div>
<div id="efficient-estimation" class="section level1">
<h1 class="hasAnchor">
<a href="#efficient-estimation" class="anchor"></a>Efficient Estimation</h1>
<p><span class="citation">Dı́az et al. (2020)</span> define two efficient estimators of their interventional (in)direct effects. These are based on the one-step estimation and targeted minimum loss (TML) estimation frameworks, respectively. Briefly, both estimation strategies proceed in two stages, starting by first constructing initial estimates of the nuisance parameters present in the EIF, then proceeding to apply distinct bias-correction strategies in their second stages. Both estimation strategies require an assumption about the behavior of initial estimators of the nuisance parameters (specifically, that these lie in a Donsker class); however, the need for such an assumption may be avoided by making use of cross-validation in the fitting fo initial estimators. The <code>medoutcon</code> <code>R</code> package requires the use of cross-validation in the construction of these initial estimates, resulting in cross-fitted one-step and and cross-validated TML estimators <span class="citation">(Klaassen 1987; Zheng and van der Laan 2011; Chernozhukov et al. 2018)</span>.</p>
<p>The one-step estimator <span class="math inline">\(\hat{\theta}_{\text{os}}\)</span> is constructed by adding the empirical mean of the EIF (evaluated at initial estimates of the nuisance parameters) to the substitution estimator. By constrast, the TML estimator <span class="math inline">\(\hat{\theta}_{\text{tmle}}\)</span> updates the components of the substitution estimator via logistic tilting models formulated to ensure that relevant score equations appearing in the EIF are (approximately) solved. While the estimators are asymptotically equivalent, TML estimators have been shown to exhibit superior finite-sample performance, making them potentially more reliable than one-step estimators. For the exact form of the EIF as well as those of the one-step and TML estimators, consult <span class="citation">Dı́az et al. (2020)</span>.</p>
</div>
<div id="data-analysis-example" class="section level1">
<h1 class="hasAnchor">
<a href="#data-analysis-example" class="anchor"></a>Data Analysis Example</h1>
<div id="setting-up-the-data-example" class="section level2">
<h2 class="hasAnchor">
<a href="#setting-up-the-data-example" class="anchor"></a>Setting up the data example</h2>
<p>Now, we’ll take a look at how to estimate the interventional direct and indirect effects using a simulated data example. <span class="citation">Dı́az et al. (2020)</span> illustrate the use of their estimators of these effects in an application in which they seek to elucidate the mechanisms behind the unintended harmful effects that a housing intervention had on adolescent girls’ risk behavior.</p>
<p>First, let’s load a few required packages and set a seed for our simulation.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com">data.table</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/nhejazi/medoutcon">medoutcon</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tlverse.org/sl3">sl3</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">75681</span><span class="op">)</span>
<span class="va">n_obs</span> <span class="op">&lt;-</span> <span class="fl">500</span>      <span class="co"># number of observations in our simulated dataset</span></code></pre></div>
<p>Next, we’ll generate a very simple simulated dataset. The function <code>make_example_data</code>, defined below, generates three binary baseline covariates <span class="math inline">\(W = (W_1, W_2, W_3)\)</span>, a binary exposure variable <span class="math inline">\(A\)</span>, a single binary mediateor <span class="math inline">\(M\)</span> an intermediate confounder <span class="math inline">\(Z\)</span> that affects the mediator <span class="math inline">\(M\)</span> and is itself affected by the exposure <span class="math inline">\(A\)</span>, and, finally, a binary outcome <span class="math inline">\(Y\)</span> that is a function of <span class="math inline">\((W, A, Z, M)\)</span>.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># produces a simple data set based on ca causal model with mediation</span>
<span class="va">make_example_data</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n_obs</span> <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span> <span class="op">{</span>
  <span class="co">## baseline covariates</span>
  <span class="va">w_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n_obs</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span>
  <span class="va">w_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n_obs</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span>
  <span class="va">w_3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n_obs</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">pmin</a></span><span class="op">(</span><span class="fl">0.2</span> <span class="op">+</span> <span class="op">(</span><span class="va">w_1</span> <span class="op">+</span> <span class="va">w_2</span><span class="op">)</span> <span class="op">/</span> <span class="fl">3</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
  <span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">w_1</span>, <span class="va">w_2</span>, <span class="va">w_3</span><span class="op">)</span>
  <span class="va">w_names</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"W"</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">w</span><span class="op">)</span><span class="op">)</span>, sep <span class="op">=</span> <span class="st">"_"</span><span class="op">)</span>

  <span class="co">## exposure</span>
  <span class="va">a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n_obs</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html">plogis</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">w</span><span class="op">)</span> <span class="op">-</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

  <span class="co">## mediator-outcome confounder affected by treatment</span>
  <span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n_obs</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html">plogis</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowMeans</a></span><span class="op">(</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="va">w</span> <span class="op">-</span> <span class="va">a</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.2</span><span class="op">)</span><span class="op">)</span>

  <span class="co">## mediator -- could be multivariate</span>
  <span class="va">m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n_obs</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html">plogis</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span> <span class="op">*</span> <span class="va">w</span><span class="op">[</span>, <span class="op">-</span><span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="va">a</span> <span class="op">-</span> <span class="va">z</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
  <span class="va">m_names</span> <span class="op">&lt;-</span> <span class="st">"M"</span>

  <span class="co">## outcome</span>
  <span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n_obs</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html">plogis</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">w</span><span class="op">)</span> <span class="op">-</span> <span class="va">z</span> <span class="op">+</span> <span class="va">a</span> <span class="op">+</span> <span class="va">m</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

  <span class="co">## construct output</span>
  <span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span>w <span class="op">=</span> <span class="va">w</span>, a <span class="op">=</span> <span class="va">a</span>, z <span class="op">=</span> <span class="va">z</span>, m <span class="op">=</span> <span class="va">m</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span>
  <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/setattr.html">setnames</a></span><span class="op">(</span><span class="va">dat</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">w_names</span>, <span class="st">"A"</span>, <span class="st">"Z"</span>, <span class="va">m_names</span>, <span class="st">"Y"</span><span class="op">)</span><span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>
<span class="op">}</span>

<span class="co"># set seed and simulate example data</span>
<span class="va">example_data</span> <span class="op">&lt;-</span> <span class="fu">make_example_data</span><span class="op">(</span><span class="va">n_obs</span><span class="op">)</span>
<span class="va">w_names</span> <span class="op">&lt;-</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_subset.html">str_subset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">example_data</span><span class="op">)</span>, <span class="st">"W"</span><span class="op">)</span>
<span class="va">m_names</span> <span class="op">&lt;-</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_subset.html">str_subset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">example_data</span><span class="op">)</span>, <span class="st">"M"</span><span class="op">)</span></code></pre></div>
<p>Now, let’s take a quick look at our simulated data:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># quick look at the data</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">example_data</span><span class="op">)</span></code></pre></div>
<pre><code>##    W_1 W_2 W_3 A Z M Y
## 1:   0   0   1 0 0 0 1
## 2:   0   1   1 0 0 0 1
## 3:   1   1   0 0 1 1 1
## 4:   1   0   1 0 1 0 0
## 5:   0   0   0 1 1 1 1
## 6:   1   0   1 1 0 1 1</code></pre>
<p>As noted above, all covariates in our dataset are binary; however, note that this need not be the case for using our methodology — in particular, the only current limitation is that the intermediate confounder <span class="math inline">\(Z\)</span> must be binary when using our implemented TML estimator of the (in)direct effects.</p>
<p>Using this dataset, we’ll proceed to estimate the interventional (in)direct effects. In order to do so, we’ll need to estimate several nuisance parameters, including the exposure mechanism <span class="math inline">\(g(A \mid W)\)</span>, a re-parameterized exposure mechanism that conditions on the mediators <span class="math inline">\(h(A \mid M, W)\)</span>, the outcome mechanism <span class="math inline">\(b(Y \mid M, Z, A, W)\)</span>, and two variants of the intermediate confounding mechanism <span class="math inline">\(q(Z \mid A, W)\)</span> and <span class="math inline">\(r(Z \mid M, A, W)\)</span>. In order to estimate each of these nuisance parameters flexibly, we’ll rely on data adaptive regression strategies in order to avoid the potential for (parametric) model misspecification.</p>
<!--
Note that there are two additional nuisance parameters that must also be
estimated ($u$ and $v$), which are themselves functions of the other nuisance
parameters.  We recommend estimating these via the highly adaptive lasso, which
is the...
-->
</div>
<div id="ensemble-learning-of-nuisance-functions" class="section level2">
<h2 class="hasAnchor">
<a href="#ensemble-learning-of-nuisance-functions" class="anchor"></a>Ensemble learning of nuisance functions</h2>
<p>As we’d like to rely on flexible, data adaptive regression strategies for estimating each of the nuisance parameters <span class="math inline">\((g, h, b, q, r)\)</span>, we require a method for choosing among or combining the wide variety of available regression strategies. For this, we recommend the use of the Super Learner algorithm for ensemble machine learning <span class="citation">(van der Laan, Polley, and Hubbard 2007)</span>. The recently developed <a href="https://tlverse.org/sl3"><code>sl3</code> R package</a> <span class="citation">(Coyle et al. 2020)</span> provides a unified interface for deploying a wide variety of machine learning algorithms (simply called <em>learners</em> in the <code>sl3</code> nomenclature) as well as for constructing Super Learner ensemble models of such learners. For a complete guide on using the <code>sl3</code> R package, consider consulting <a href="https://tlverse.org/sl3" class="uri">https://tlverse.org/sl3</a>, or <a href="https://tlverse.org" class="uri">https://tlverse.org</a> (and <a href="https://github.com/tlverse" class="uri">https://github.com/tlverse</a>) for the <code>tlverse</code> ecosystem, of which <code>sl3</code> is an integral part.</p>
<p>To construct an ensemble learner using a handful of popular machine learning algorithms, we’ll first instantiate variants of learners from the appropriate classes for each algorithm, and then create a Super Learner ensemble via the <code>Lrnr_sl</code> class. Below, we demonstrate the construction of an ensemble learner based on a modeling library including an intercept model, a main-terms GLM, <span class="math inline">\(\ell_1\)</span>-penalized Lasso regression, <span class="math inline">\(\ell_2\)</span>-penalized ridge regression, an elastic net regression that equally weights the <span class="math inline">\(\ell_1\)</span> and <span class="math inline">\(\ell_2\)</span> penalties, extreme gradient boosted trees (<code>xgboost</code>), and the highly adaptive lasso (HAL):</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># instantiate learners</span>
<span class="va">mean_lrnr</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_mean.html">Lrnr_mean</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="va">fglm_lrnr</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glm_fast.html">Lrnr_glm_fast</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
<span class="va">lasso_lrnr</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">1</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, nfolds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="va">enet_lrnr</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, nfolds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="va">rf_lrnr</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_ranger.html">Lrnr_ranger</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>num.trees <span class="op">=</span> <span class="fl">200</span><span class="op">)</span>

<span class="co"># for HAL, use linear probability formulation, with bounding in unit interval</span>
<span class="va">hal_gaussian_lrnr</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_hal9001.html">Lrnr_hal9001</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  family <span class="op">=</span> <span class="st">"gaussian"</span>,
  fit_control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
    n_folds <span class="op">=</span> <span class="fl">3</span>,
    use_min <span class="op">=</span> <span class="cn">TRUE</span>,
    type.measure <span class="op">=</span> <span class="st">"mse"</span>,
    lambda.min.ratio <span class="op">=</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n_obs</span>
  <span class="op">)</span>
<span class="op">)</span>
<span class="va">bound_lrnr</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_bound.html">Lrnr_bound</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>bound <span class="op">=</span> <span class="fl">1e-6</span><span class="op">)</span>
<span class="va">hal_bounded_lrnr</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Pipeline.html">Pipeline</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">hal_gaussian_lrnr</span>, <span class="va">bound_lrnr</span><span class="op">)</span>

<span class="co"># create learner library and instantiate super learner ensemble</span>
<span class="va">lrnr_lib</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Stack.html">Stack</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">mean_lrnr</span>, <span class="va">fglm_lrnr</span>, <span class="va">enet_lrnr</span>, <span class="va">lasso_lrnr</span>,
                      <span class="va">rf_lrnr</span>, <span class="va">hal_bounded_lrnr</span><span class="op">)</span>
<span class="va">sl_lrnr</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_sl.html">Lrnr_sl</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>learners <span class="op">=</span> <span class="va">lrnr_lib</span>, metalearner <span class="op">=</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_nnls.html">Lrnr_nnls</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>While we recommend the use of a Super Learner ensemble model like the one constructed above in practice, such a library will be too computationally intensive for our examples. To reduce computation time, we construct a simpler library, using only a subset of the above learning algorithms:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># create simpler learner library and instantiate super learner ensemble</span>
<span class="va">lrnr_lib</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Stack.html">Stack</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">mean_lrnr</span>, <span class="va">fglm_lrnr</span>, <span class="va">lasso_lrnr</span>, <span class="va">rf_lrnr</span><span class="op">)</span>
<span class="va">sl_lrnr</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_sl.html">Lrnr_sl</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>learners <span class="op">=</span> <span class="va">lrnr_lib</span>, metalearner <span class="op">=</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_nnls.html">Lrnr_nnls</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Having set up our ensemble learner, we’re now ready to estimate each of the interventional effects using the efficient estimators exposed in the <code>medoutcon</code> package.</p>
</div>
<div id="estimating-the-direct-effect" class="section level2">
<h2 class="hasAnchor">
<a href="#estimating-the-direct-effect" class="anchor"></a>Estimating the direct effect</h2>
<p>We’re now ready to estimate the interventional direct effect. This direct effect is computed as a contrast between the interventions <span class="math inline">\((a' = 1, a^{\star} = 0)\)</span> and <span class="math inline">\((a' = 0, a^{\star} = 0)\)</span>. In particular, our efficient estimators of the interventional direct effect proceed by constructing estimators <span class="math inline">\(\hat{\theta}(a' = 1, a^{\star} = 0)\)</span> and <span class="math inline">\(\hat{\theta}(a' = 0, a^{\star} = 0)\)</span>. Then, an efficient estimator of the direct effect is available by application of the delta method, that is, <span class="math inline">\(\hat{\theta}^{\text{DE}} = \hat{\theta}(a' = 1, a^{\star} = 0) - \hat{\theta}(a' = 0, a^{\star} = 0)\)</span>. Applying the same principle to the EIF estimates, one can derive variance estimates and construct asymptotically correct Wald-style confidence intervals for <span class="math inline">\(\hat{\theta}^{\text{DE}}\)</span>.</p>
<p>The <code>medoutcon</code> package makes the estimation task quite simple, as only a single call to the eponymous <code>medoutcon</code> function is required. As demonstrated below, we need only feed in each component of the observed data <span class="math inline">\(O = (W, A, Z, M, Y)\)</span> (of which <span class="math inline">\(W\)</span> and <span class="math inline">\(M\)</span> can be multivariate), specify the effect type, and the estimator. Additionally, for each nuisance parameter we may specify a separate regression function — in the examples below, we use the simpler Super Learner ensemble constructed above for fitting each nuisance function, but this need not be the case (i.e., different estimators may be used for each nuisance function).</p>
<p>First, we examine the one-step estimator of the interventional direct effect. Recall that the one-step estimator is constructed by adding the mean of the EIF (evaluated at initial estimates of the nuisance parameters) to the substitution estimator. As noted above, this is done separately for each of the two contrasts <span class="math inline">\((a' = 0, a^{\star} = 0)\)</span> and <span class="math inline">\((a' = 1, a^{\star} = 0)\)</span>. Thus, the one-step estimator of this direct effect is constructed by application of the delta method to each of the one-step estimators (and EIFs) for these contrasts.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># compute one-step estimate of the interventional direct effect</span>
<span class="va">os_de</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/medoutcon.html">medoutcon</a></span><span class="op">(</span>W <span class="op">=</span> <span class="va">example_data</span><span class="op">[</span>, <span class="va">..w_names</span><span class="op">]</span>,
                   A <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">A</span>,
                   Z <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">Z</span>,
                   M <span class="op">=</span> <span class="va">example_data</span><span class="op">[</span>, <span class="va">..m_names</span><span class="op">]</span>,
                   Y <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">Y</span>,
                   g_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                   h_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                   b_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                   q_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                   r_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                   effect <span class="op">=</span> <span class="st">"direct"</span>,
                   estimator <span class="op">=</span> <span class="st">"onestep"</span>,
                   estimator_args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>cv_folds <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">os_de</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 7
##   lwr_ci param_est upr_ci var_est  eif_mean estimator param                
##    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                
## 1 -0.122  -0.00644  0.109 0.00348 -2.66e-17 onestep   direct_interventional</code></pre>
<p>From the output of the summary method, we note that the one-step estimate of the interventional direct effect <span class="math inline">\(\hat{\theta}_{\text{os}}^{\text{DE}}\)</span> is -0.006, with 95% confidence interval [-0.122, 0.109].</p>
<p>Next, let’s compare the one-step estimate to the TML estimate. Analogous to the case of the one-step estimator, the TML estimator can be evaluated via a single call to the <code>medoutcon</code> function:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># compute targeted minimum loss estimate of the interventional direct effect</span>
<span class="va">tmle_de</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/medoutcon.html">medoutcon</a></span><span class="op">(</span>W <span class="op">=</span> <span class="va">example_data</span><span class="op">[</span>, <span class="va">..w_names</span><span class="op">]</span>,
                     A <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">A</span>,
                     Z <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">Z</span>,
                     M <span class="op">=</span> <span class="va">example_data</span><span class="op">[</span>, <span class="va">..m_names</span><span class="op">]</span>,
                     Y <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">Y</span>,
                     g_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                     h_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                     b_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                     q_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                     r_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                     effect <span class="op">=</span> <span class="st">"direct"</span>,
                     estimator <span class="op">=</span> <span class="st">"tmle"</span>,
                     estimator_args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>cv_folds <span class="op">=</span> <span class="fl">2</span>, max_iter <span class="op">=</span> <span class="fl">5</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">tmle_de</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 7
##    lwr_ci param_est upr_ci var_est eif_mean estimator param                
##     &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                
## 1 -0.0949    0.0113  0.118 0.00294  0.00870 tmle      direct_interventional</code></pre>
<p>From the output of the summary method, we note that the TML estimate of the interventional direct effect <span class="math inline">\(\hat{\theta}_{\text{tmle}}^{\text{DE}}\)</span> is 0.011, with 95% confidence interval [-0.095, 0.118]. Here, we recall that the TML estimator generally exhibits better finite-sample performance than the one-step estimator <span class="citation">(van der Laan and Rose 2011, 2018)</span>, so the TML estimate is likely to be more reliable in our modest sample size of <span class="math inline">\(n =\)</span> 500.</p>
</div>
<div id="estimating-the-indirect-effect" class="section level2">
<h2 class="hasAnchor">
<a href="#estimating-the-indirect-effect" class="anchor"></a>Estimating the indirect effect</h2>
<p>Estimation of the interventional indirect effect proceeds similarly to the strategy discussed above for the corresponding direct effect. An efficient estimator can be computed as a contrast between the interventions <span class="math inline">\((a' = 1, a^{\star} = 0)\)</span> and <span class="math inline">\((a' = 1, a^{\star} = 1)\)</span>. Specifically, our efficient estimators of the interventional indirect effect proceed by constructing estimators <span class="math inline">\(\hat{\theta}(a' = 1, a^{\star} = 0)\)</span> and <span class="math inline">\(\hat{\theta}(a' = 1, a^{\star} = 1)\)</span>. Then, application of the delta method yields an efficient estimator of the indirect effect, that is, <span class="math inline">\(\hat{\theta}^{\text{IE}} = \hat{\theta}(a' = 1, a^{\star} = 0) - \hat{\theta}(a' = 1, a^{\star} = 1)\)</span>. The same principle may be applied to the EIF estimates to derive variance estimates and construct asymptotically correct Wald-style confidence intervals for <span class="math inline">\(\hat{\theta}^{\text{IE}}\)</span>.</p>
<p>Now, we examine the one-step estimator of the interventional indirect effect. The one-step estimator is constructed by adding the mean of the EIF (evaluated at initial estimates of the nuisance parameters) to the substitution estimator. As noted above, this is done separately for each of the two contrasts <span class="math inline">\((a' = 1, a^{\star} = 1)\)</span> and <span class="math inline">\((a' = 1, a^{\star} = 0)\)</span>. Thus, the one-step estimator of this indirect effect is constructed by application of the delta method to each of the one-step estimators (and EIFs) for the contrasts.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># compute one-step estimate of the interventional indirect effect</span>
<span class="va">os_ie</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/medoutcon.html">medoutcon</a></span><span class="op">(</span>W <span class="op">=</span> <span class="va">example_data</span><span class="op">[</span>, <span class="va">..w_names</span><span class="op">]</span>,
                   A <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">A</span>,
                   Z <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">Z</span>,
                   M <span class="op">=</span> <span class="va">example_data</span><span class="op">[</span>, <span class="va">..m_names</span><span class="op">]</span>,
                   Y <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">Y</span>,
                   g_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                   h_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                   b_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                   q_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                   r_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                   effect <span class="op">=</span> <span class="st">"indirect"</span>,
                   estimator <span class="op">=</span> <span class="st">"onestep"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">os_ie</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 7
##   lwr_ci param_est  upr_ci var_est eif_mean estimator param                  
##    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                  
## 1 -0.189    -0.119 -0.0489 0.00128 9.55e-17 onestep   indirect_interventional</code></pre>
<p>From the output of the summary method, we note that the one-step estimate of the interventional indirect effect <span class="math inline">\(\hat{\theta}_{\text{os}}^{\text{IE}}\)</span> is -0.119, with 95% confidence interval [-0.189, -0.049].</p>
<p>As before, let’s compare the one-step estimate to the TML estimate. Analogous to the case of the one-step estimator, the TML estimator can be evaluated via a single call to the <code>medoutcon</code> function, as demonstrated below</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># compute targeted minimum loss estimate of the interventional indirect effect</span>
<span class="va">tmle_ie</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/medoutcon.html">medoutcon</a></span><span class="op">(</span>W <span class="op">=</span> <span class="va">example_data</span><span class="op">[</span>, <span class="va">..w_names</span><span class="op">]</span>,
                     A <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">A</span>,
                     Z <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">Z</span>,
                     M <span class="op">=</span> <span class="va">example_data</span><span class="op">[</span>, <span class="va">..m_names</span><span class="op">]</span>,
                     Y <span class="op">=</span> <span class="va">example_data</span><span class="op">$</span><span class="va">Y</span>,
                     g_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                     h_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                     b_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                     q_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                     r_learners <span class="op">=</span> <span class="va">sl_lrnr</span>,
                     effect <span class="op">=</span> <span class="st">"indirect"</span>,
                     estimator <span class="op">=</span> <span class="st">"tmle"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">tmle_ie</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 7
##   lwr_ci param_est  upr_ci var_est  eif_mean estimator param                  
##    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                  
## 1 -0.200    -0.120 -0.0394 0.00167 -0.000267 tmle      indirect_interventional</code></pre>
<p>From the output of the summary method, we note that the TML estimate of the interventional indirect effect <span class="math inline">\(\hat{\theta}_{\text{tmle}}^{\text{IE}}\)</span> is -0.12, with 95% confidence interval [-0.2, -0.039]. As before, the TML estimator provides better finite-sample performance than the one-step estimator, so it may be preferred in this example.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references">
<div id="ref-chernozhukov2018double">
<p>Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. “Double/Debiased Machine Learning for Treatment and Structural Parameters.” <em>The Econometrics Journal</em> 21 (1). <a href="https://doi.org/10.1111/ectj.12097">https://doi.org/10.1111/ectj.12097</a>.</p>
</div>
<div id="ref-coyle2020sl3">
<p>Coyle, Jeremy R, Nima S Hejazi, Ivana Malenica, and Oleg Sofrygin. 2020. “<code>sl3</code>: Modern Pipelines for Machine Learning and Super Learning.” <a href="https://github.com/tlverse/sl3">https://github.com/tlverse/sl3</a>. <a href="https://doi.org/10.5281/zenodo.1342293">https://doi.org/10.5281/zenodo.1342293</a>.</p>
</div>
<div id="ref-diaz2020nonparametric">
<p>Dı́az, Iván, Nima S Hejazi, Kara E Rudolph, and Mark J van der Laan. 2020. “Non-Parametric Efficient Causal Mediation with Intermediate Confounders.” <em>Biometrika</em>. <a href="https://doi.org/10.1093/biomet/asaa085">https://doi.org/10.1093/biomet/asaa085</a>.</p>
</div>
<div id="ref-klaassen1987consistent">
<p>Klaassen, Chris AJ. 1987. “Consistent Estimation of the Influence Function of Locally Asymptotically Linear Estimators.” <em>The Annals of Statistics</em>, 1548–62.</p>
</div>
<div id="ref-rudolph2017robust">
<p>Rudolph, Kara E, Oleg Sofrygin, Wenjing Zheng, and Mark J van der Laan. 2017. “Robust and Flexible Estimation of Stochastic Mediation Effects: A Proposed Method and Example in a Randomized Trial Setting.” <em>Epidemiologic Methods</em> 7 (1).</p>
</div>
<div id="ref-vdl2007super">
<p>van der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. “Super Learner.” <em>Statistical Applications in Genetics and Molecular Biology</em> 6 (1).</p>
</div>
<div id="ref-vdl2011targeted">
<p>van der Laan, Mark J, and Sherri Rose. 2011. <em>Targeted Learning: Causal Inference for Observational and Experimental Data</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-vdl2018targeted">
<p>———. 2018. <em>Targeted Learning in Data Science: Causal Inference for Complex Longitudinal Studies</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-vanderweele2014effect">
<p>VanderWeele, Tyler J, Stijn Vansteelandt, and James M Robins. 2014. “Effect Decomposition in the Presence of an Exposure-Induced Mediator-Outcome Confounder.” <em>Epidemiology (Cambridge, Mass.)</em> 25 (2): 300.</p>
</div>
<div id="ref-zheng2011cross">
<p>Zheng, Wenjing, and Mark J van der Laan. 2011. “Cross-Validated Targeted Minimum-Loss-Based Estimation.” In <em>Targeted Learning</em>, 459–74. Springer.</p>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Nima Hejazi, Iván Díaz, Kara Rudolph.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
